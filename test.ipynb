{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxmnu8O92bM57EHDP57H/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panperception/SALSA_Test/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SALSA Tests"
      ],
      "metadata": {
        "id": "ANnLAudKsiOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/verde.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdDawSW7v2-R",
        "outputId": "0e0b0150-f746-4af7-fd4e-d6f5ca89e69c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'verde'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 41 (delta 3), reused 36 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (41/41), 70.52 KiB | 2.82 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd verde"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8OBm-f48j-B",
        "outputId": "fc61db38-ffde-413e-b79a-315a0fcf7726"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/verde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "import json\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import src\n",
        "from src.slurm import init_signal_handler, init_distributed_mode\n",
        "from src.utils import bool_flag, initialize_exp\n",
        "from src.train.model import check_model_params, build_modules\n",
        "from src.train.trainer import Trainer\n",
        "from src.train.evaluator import Evaluator\n",
        "from src.train.envs.generators import RLWE\n",
        "from src.train.envs.lattice import LatticeEnvironment\n",
        "from src.train.envs.datasets import create_dataloader\n",
        "\n",
        "np.seterr(all='raise')\n",
        "\n",
        "\n",
        "def get_parser():\n",
        "    \"\"\"\n",
        "    Generate a parameters parser.\n",
        "    \"\"\"\n",
        "    # parse parameters\n",
        "    parser = argparse.ArgumentParser(description=\"Language transfer\")\n",
        "\n",
        "    # main parameters\n",
        "    parser.add_argument(\"--dump_path\", type=str, default=\"\",\n",
        "                        help=\"Experiment dump path\")\n",
        "    parser.add_argument(\"--exp_name\", type=str, default=\"debug\",\n",
        "                        help=\"Experiment name\")\n",
        "    parser.add_argument(\"--exp_id\", type=str, default=\"\",\n",
        "                        help=\"Experiment ID\")\n",
        "\n",
        "    # float16 / AMP API\n",
        "    parser.add_argument(\"--fp16\", type=bool_flag, default=True,\n",
        "                        help=\"Run model with float16\")\n",
        "    parser.add_argument(\"--amp\", type=int, default=2,\n",
        "                        help=\"Use AMP wrapper for float16 / distributed / gradient accumulation. Level of optimization. -1 to disable.\")\n",
        "\n",
        "    # Hamming parameters\n",
        "    parser.add_argument(\"--max_output_len\", type=int, default=10,\n",
        "                        help=\"max length of output, beam max size\")\n",
        "    parser.add_argument(\"--hamming\", type=int, default=4,\n",
        "                        help=\"Hamming weight of the secret\")\n",
        "    parser.add_argument(\"--secret_seed\", type=int, default=0,\n",
        "                        help=\"Use dataset generated with this secret seed\")\n",
        "\n",
        "    # load data\n",
        "    parser.add_argument(\"--reload_data\", type=str, default=\"\",\n",
        "                        help=\"The directory that has data.prefix to load dataset from the disk\")\n",
        "    parser.add_argument(\"--reload_size\", type=int, default=10000000,\n",
        "                        help=\"Reloaded training set size, default large to load all data\")\n",
        "    parser.add_argument(\"--batch_load\", type=bool_flag, default=False,\n",
        "                        help=\"Load training set by batches (of size reload_size)\")\n",
        "    parser.add_argument(\"--shuffle\", type=bool_flag, default=True,\n",
        "                        help=\"Shuffle when loading the train data\")\n",
        "    parser.add_argument(\"--dim_red\", type=str, default=\"\",\n",
        "                        help=\"file to read columns for dimension reduction\")\n",
        "    parser.add_argument(\"--add_unred_perc\", type=int, default=0,\n",
        "                        help=\"percentage of adding random linear combinations of original data to the train set\")\n",
        "\n",
        "    # Reuse samples\n",
        "    parser.add_argument(\"--reuse\", type=bool_flag, default=False,\n",
        "                        help='reuse samples during training?')\n",
        "    parser.add_argument(\"--num_reuse_samples\", type=int, default=10000,\n",
        "                        help='number of samples to choose from during one reuse batch')\n",
        "    parser.add_argument(\"--times_reused\", type=int, default=10,\n",
        "                        help='how many times to reuse a sample before discarding it?')\n",
        "\n",
        "    # Bases\n",
        "    parser.add_argument(\"--balanced_base\", type=bool_flag, default=False,\n",
        "                        help=\"use balanced base?\")\n",
        "    parser.add_argument(\"--input_int_base\", type=int, default=81,\n",
        "                        help=\"base of the input encoder\")\n",
        "    parser.add_argument(\"--output_int_base\", type=int, default=0,\n",
        "                        help=\"base of the output encoder\")\n",
        "    parser.add_argument(\"--correctQ\", type=bool_flag, default=False,\n",
        "                        help='flip the Q range to be within -Q/2 and Q/2?')\n",
        "    parser.add_argument(\"--share_token\", type=int, default=1,\n",
        "                        help=\"if set to k, each k numbers at the less significant bit will share the same token\")\n",
        "\n",
        "    # model parameters\n",
        "    parser.add_argument(\"--transformermode\", type=str, default='old',\n",
        "                        help=\"old for the old transformer\")\n",
        "    parser.add_argument(\"--enc_emb_dim\", type=int, default=1024,\n",
        "                        help=\"Encoder embedding layer size\")\n",
        "    parser.add_argument(\"--dec_emb_dim\", type=int, default=512,\n",
        "                        help=\"Decoder embedding layer size\")\n",
        "    parser.add_argument(\"--n_enc_layers\", type=int, default=1,\n",
        "                        help=\"Number of Transformer layers in the encoder\")\n",
        "    parser.add_argument(\"--n_dec_layers\", type=int, default=2,\n",
        "                        help=\"Number of Transformer layers in the decoder\")\n",
        "    parser.add_argument(\"--n_enc_heads\", type=int, default=4,\n",
        "                        help=\"Number of Transformer encoder heads\")\n",
        "    parser.add_argument(\"--n_dec_heads\", type=int, default=4,\n",
        "                        help=\"Number of Transformer decoder heads\")\n",
        "    parser.add_argument(\"--n_cross_heads\", type=int, default=4,\n",
        "                        help=\"Number of Transformer decoder heads in the cross attention\")\n",
        "    parser.add_argument(\"--n_enc_hidden_layers\", type=int, default=1,\n",
        "                        help=\"Number of FFN layers in Transformer encoder\")\n",
        "    parser.add_argument(\"--n_dec_hidden_layers\", type=int, default=1,\n",
        "                        help=\"Number of FFN layers in Transformer decoder\")\n",
        "    parser.add_argument(\"--xav_init\", type=bool_flag, default=False,\n",
        "                        help=\"Xavier initialization for transformer parameters\")\n",
        "    parser.add_argument(\"--gelu_activation\", type=bool_flag, default=False,\n",
        "                        help=\"GELU initialization in FFN layers (else RELU)\")\n",
        "\n",
        "    parser.add_argument(\"--norm_attention\", type=bool_flag, default=False,\n",
        "                        help=\"Normalize attention and train temperature in Transformer\")\n",
        "    parser.add_argument(\"--dropout\", type=float, default=0,\n",
        "                        help=\"Dropout\")\n",
        "    parser.add_argument(\"--attention_dropout\", type=float, default=0,\n",
        "                        help=\"Dropout in the attention layer\")\n",
        "    parser.add_argument(\"--share_inout_emb\", type=bool_flag, default=True,\n",
        "                        help=\"Share input and output embeddings\")\n",
        "    parser.add_argument(\"--sinusoidal_embeddings\", type=bool_flag, default=False,\n",
        "                        help=\"Use sinusoidal embeddings\")\n",
        "\n",
        "    # universal transformer parameters\n",
        "    parser.add_argument(\"--enc_loop_idx\", type=int, default=-1,\n",
        "                        help=\"Index of the encoder shared weight layers (-1 for none)\")\n",
        "    parser.add_argument(\"--dec_loop_idx\", type=int, default=0,\n",
        "                        help=\"Index of the decoder shared weight layers (-1 for none)\")\n",
        "    parser.add_argument(\"--enc_loops\", type=int, default=1,\n",
        "                        help=\"Fixed/max nr of train passes through the encoder loop\")\n",
        "    parser.add_argument(\"--dec_loops\", type=int, default=8,\n",
        "                        help=\"Fixed/max nr of train passes through the decoder loop\")\n",
        "    parser.add_argument(\"--gated\", type=bool_flag, default=True,\n",
        "                        help=\"Gated loop layers\")\n",
        "    parser.add_argument(\"--enc_gated\", type=bool_flag, default=False,\n",
        "                        help=\"All encoder layers gated\")\n",
        "    parser.add_argument(\"--dec_gated\", type=bool_flag, default=False,\n",
        "                        help=\"All decoder layers gated\")\n",
        "    parser.add_argument(\"--scalar_gate\", type=bool_flag, default=False,\n",
        "                        help=\"Scalar gates\")\n",
        "\n",
        "    # ACT\n",
        "    parser.add_argument(\"--enc_act\", type=bool_flag, default=False,\n",
        "                        help=\"Encoder looped layer ACT\")\n",
        "    parser.add_argument(\"--dec_act\", type=bool_flag, default=False,\n",
        "                        help=\"Decoder looped layer ACT\")\n",
        "    parser.add_argument(\"--act_threshold\", type=float, default=0.01,\n",
        "                        help=\"Prob threshold for ACT\")\n",
        "    parser.add_argument(\"--act_ponder_coupling\", type=float, default=0.05,\n",
        "                        help=\"Ponder loss coupling for ACT\")\n",
        "\n",
        "    # training parameters\n",
        "    parser.add_argument(\"--env_base_seed\", type=int, default=-1,\n",
        "                        help=\"Base seed for environments (-1 to use timestamp seed)\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128,\n",
        "                        help=\"Number of sentences per batch\")\n",
        "    parser.add_argument(\"--optimizer\", type=str, default=\"adam_warmup,lr=0.00001,warmup_updates=8000,weight_decay=0.99\",\n",
        "                        help=\"Optimizer (SGD / RMSprop / Adam, etc.)\")\n",
        "    parser.add_argument(\"--weighted_loss\", type=bool_flag, default=False,\n",
        "                        help='Weight loss to emphasize higher bits?')\n",
        "    parser.add_argument(\"--clip_grad_norm\", type=float, default=5,\n",
        "                        help=\"Clip gradients norm (0 to disable)\")\n",
        "    parser.add_argument(\"--epoch_size\", type=int, default=2000000,\n",
        "                        help=\"Epoch size / evaluation frequency\")\n",
        "    parser.add_argument(\"--max_epoch\", type=int, default=20,\n",
        "                        help=\"Maximum number of epochs\")\n",
        "    parser.add_argument(\"--stopping_criterion\", type=str, default=\"\",\n",
        "                        help=\"Stopping criterion, and number of non-increase before stopping the experiment\")\n",
        "\n",
        "    parser.add_argument(\"--validation_metrics\", type=str, default=\"\",\n",
        "                        help=\"Validation metrics\")\n",
        "    parser.add_argument(\"--accumulate_gradients\", type=int, default=1,\n",
        "                        help=\"Accumulate model gradients over N iterations (N times larger batch sizes)\")\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=1,\n",
        "                        help=\"Number of CPU workers for DataLoader\")\n",
        "\n",
        "    # beam search configuration\n",
        "    parser.add_argument(\"--beam_eval\", type=bool_flag, default=True,\n",
        "                        help=\"Evaluate with beam search decoding.\")\n",
        "    parser.add_argument(\"--beam_eval_train\", type=int, default=0,\n",
        "                        help=\"At training time, number of validation equations to test the model on using beam search (-1 for everything, 0 to disable)\")\n",
        "    parser.add_argument(\"--beam_size\", type=int, default=1,\n",
        "                        help=\"Beam size, default = 1 (greedy decoding)\")\n",
        "    parser.add_argument(\"--beam_length_penalty\", type=float, default=1,\n",
        "                        help=\"Length penalty, values < 1.0 favor shorter sentences, while values > 1.0 favor longer ones.\")\n",
        "    parser.add_argument(\"--beam_early_stopping\", type=bool_flag, default=True,\n",
        "                        help=\"Early stopping, stop as soon as we have `beam_size` hypotheses, although longer ones may have better scores.\")\n",
        "\n",
        "    # reload pretrained model / checkpoint\n",
        "    parser.add_argument(\"--reload_model\", type=str, default=\"\",\n",
        "                        help=\"Reload a pretrained model\")\n",
        "    parser.add_argument(\"--reload_checkpoint\", type=str, default=\"\",\n",
        "                        help=\"Reload a checkpoint\")\n",
        "    parser.add_argument(\"--freeze_embeddings\", type=bool_flag, default=\"False\",\n",
        "                        help=\"Freeze embeddings for retraining?\")\n",
        "\n",
        "    # evaluation\n",
        "    parser.add_argument(\"--eval_only\", type=bool_flag, default=False,\n",
        "                        help=\"Only run evaluations\")\n",
        "    parser.add_argument(\"--eval_from_exp\", type=str, default=\"\",\n",
        "                        help=\"Path of experiment to use\")\n",
        "    parser.add_argument(\"--eval_data\", type=str, default=\"\",\n",
        "                        help=\"Path of data to eval\")\n",
        "    parser.add_argument(\"--eval_verbose\", type=int, default=0,\n",
        "                        help=\"Export evaluation details\")\n",
        "    parser.add_argument(\"--eval_verbose_print\", type=bool_flag, default=False,\n",
        "                        help=\"Print evaluation details\")\n",
        "    parser.add_argument(\"--eval_size\", type=int, default=10000,\n",
        "                        help=\"Size of valid and test samples\")\n",
        "    parser.add_argument(\"--distinguisher_size\", type=int, default=128,\n",
        "                        help=\"Size of distinguisher samples\")\n",
        "\n",
        "    # debug\n",
        "    parser.add_argument(\"--debug_slurm\", type=bool_flag, default=False,\n",
        "                        help=\"Debug multi-GPU / multi-node within a SLURM job\")\n",
        "    parser.add_argument(\"--debug\", default=False, help=\"Enable all debug flags\",\n",
        "                        action=\"store_true\")\n",
        "\n",
        "    # CPU / multi-gpu / multi-node\n",
        "    parser.add_argument(\"--cpu\", type=bool_flag, default=False,\n",
        "                        help=\"Run on CPU\")\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
        "                        help=\"Multi-GPU - Local rank\")\n",
        "    parser.add_argument(\"--master_port\", type=int, default=-1,\n",
        "                        help=\"Master port (for multi-node SLURM jobs)\")\n",
        "    parser.add_argument(\"--windows\", type=bool_flag, default=False,\n",
        "                        help=\"Windows version (no multiprocessing for eval)\")\n",
        "    parser.add_argument(\"--nvidia_apex\", type=bool_flag, default=False,\n",
        "                        help=\"NVIDIA version of apex\")\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "def parse_params(params):\n",
        "    # load params of the dataset and add them to the params of the experiment\n",
        "    paths = [os.path.join(params.reload_data, filename) for filename in ['train.prefix', 'test.prefix', 'params.pkl', 'secret.npy']]\n",
        "    for path in paths:\n",
        "        assert os.path.isfile(path)\n",
        "    params.train_path, params.test_path, params_path, secret_path = paths\n",
        "\n",
        "    env_params = pickle.load(open(params_path, 'rb'))\n",
        "    if type(env_params) != dict:\n",
        "        env_params = env_params.__dict__\n",
        "    params.N, params.Q, params.sigma = env_params['N'], env_params['Q'], env_params['sigma']\n",
        "    params.secret_type = env_params['secret_type'] if 'secret_type' in env_params else 'binary'\n",
        "    num_secret_seeds = env_params['num_secret_seeds'] if 'num_secret_seeds' in env_params else 1\n",
        "    min_h = env_params['min_hamming'] if 'min_hamming' in env_params else 3\n",
        "    secret = np.load(secret_path).T\n",
        "    params.secret_col = (params.hamming-min_h) * num_secret_seeds + params.secret_seed  # secrets start at h=3\n",
        "    params.secret = secret[params.secret_col]\n",
        "    assert sum(params.secret != 0) == params.hamming\n",
        "    dim_red_params(params)\n",
        "\n",
        "    if params.env_base_seed < 0:\n",
        "        params.env_base_seed = np.random.randint(1_000_000_000)\n",
        "    if params.output_int_base == 0:\n",
        "        params.output_int_base = params.input_int_base\n",
        "\n",
        "def dim_red_params(params):\n",
        "    if params.dim_red == \"\":\n",
        "        params.data_cols, params.dense_cols = None, None\n",
        "        return\n",
        "    assert os.path.isfile(params.dim_red)\n",
        "    dim_red = pickle.load(open(params.dim_red, 'rb'))\n",
        "    if type(dim_red) != dict:\n",
        "        dim_red = dim_red.__dict__\n",
        "    data_cols, dense_cols = dim_red[(params.reload_data, params.secret_seed, params.hamming)]\n",
        "    params.data_cols, params.dense_cols = np.array(data_cols), np.array(dense_cols)\n",
        "    # error if nonzeros are kicked out\n",
        "    assert params.hamming == sum(params.secret[params.data_cols] != 0)\n",
        "    # hamming weight reduction: flip the secret bits for the dense_cols\n",
        "    if len(params.dense_cols) > 0:\n",
        "        params.secret[params.dense_cols] -= 1\n",
        "        params.secret[params.dense_cols] *= -1\n",
        "    # dimension reduction: keep a subset of the columns\n",
        "    params.secret = params.secret[params.data_cols]\n",
        "    params.hamming = sum(params.secret != 0)\n",
        "    params.N = len(params.data_cols)\n",
        "\n",
        "def build_all(params):\n",
        "    generator = RLWE(params)\n",
        "\n",
        "    env = LatticeEnvironment(params, generator)\n",
        "    modules = build_modules(env, params)\n",
        "\n",
        "    if not params.eval_only:\n",
        "        train_dataloader = create_dataloader(params, env, 'train')\n",
        "    else:\n",
        "        train_dataloader = None\n",
        "    test_dataloader = create_dataloader(params, env, 'test')\n",
        "\n",
        "    trainer = Trainer(params, modules, env, train_dataloader)\n",
        "    evaluator = Evaluator(trainer, test_dataloader)\n",
        "\n",
        "    return trainer, evaluator\n",
        "\n",
        "def main(params):\n",
        "\n",
        "    # initialize the multi-GPU / multi-node training\n",
        "    # initialize experiment / SLURM signal handler for time limit / pre-emption\n",
        "    init_distributed_mode(params)\n",
        "    logger = initialize_exp(params)\n",
        "    if params.is_slurm_job:\n",
        "        init_signal_handler()\n",
        "\n",
        "    # CPU / CUDA\n",
        "    if params.cpu:\n",
        "        assert not params.multi_gpu\n",
        "    else:\n",
        "        assert torch.cuda.is_available()\n",
        "    src.utils.CUDA = not params.cpu\n",
        "\n",
        "    # build environment / modules / trainer / evaluator\n",
        "    trainer, evaluator = build_all(params)\n",
        "\n",
        "    # evaluation\n",
        "    if params.eval_only:\n",
        "        scores = evaluator.run_all_evals()\n",
        "        for k, v in scores.items():\n",
        "            logger.info(\"%s -> %.6f\" % (k, v))\n",
        "        logger.info(\"__log__:%s\" % json.dumps(scores))\n",
        "        exit()\n",
        "\n",
        "    # training\n",
        "    while trainer.epoch < params.max_epoch:\n",
        "\n",
        "        logger.info(\"============ Starting epoch %i ... ============\" % trainer.epoch)\n",
        "\n",
        "        trainer.n_equations = 0\n",
        "\n",
        "        while trainer.n_equations < trainer.epoch_size:\n",
        "            trainer.enc_dec_step()\n",
        "            trainer.iter()\n",
        "\n",
        "        logger.info(\"============ End of epoch %i ============\" % trainer.epoch)\n",
        "\n",
        "\n",
        "        # evaluate perplexity\n",
        "        scores = evaluator.run_all_evals()\n",
        "\n",
        "        # print / JSON log\n",
        "        if params.is_master:\n",
        "            logger.info(\"__log__:%s\" % json.dumps(scores))\n",
        "\n",
        "        # end of epoch\n",
        "        trainer.save_best_model(scores)\n",
        "        trainer.end_epoch(scores)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # generate parser / parse parameters\n",
        "    parser = get_parser()\n",
        "    params = parser.parse_args()\n",
        "    parse_params(params)\n",
        "\n",
        "    # debug mode\n",
        "    if params.debug:\n",
        "        params.exp_name = 'debug'\n",
        "        if params.exp_id == '':\n",
        "            params.exp_id = 'debug_%08i' % random.randint(0, 100000000)\n",
        "        params.debug_slurm = True\n",
        "\n",
        "    # check parameters\n",
        "    check_model_params(params)\n",
        "\n",
        "    # run experiment\n",
        "    main(params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "ysdr5p8BxJCd",
        "outputId": "847bbc2d-4ee6-4a49-d250-301aaf9b5ed7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--dump_path DUMP_PATH] [--exp_name EXP_NAME]\n",
            "                                [--exp_id EXP_ID] [--fp16 FP16] [--amp AMP]\n",
            "                                [--max_output_len MAX_OUTPUT_LEN] [--hamming HAMMING]\n",
            "                                [--secret_seed SECRET_SEED] [--reload_data RELOAD_DATA]\n",
            "                                [--reload_size RELOAD_SIZE] [--batch_load BATCH_LOAD]\n",
            "                                [--shuffle SHUFFLE] [--dim_red DIM_RED]\n",
            "                                [--add_unred_perc ADD_UNRED_PERC] [--reuse REUSE]\n",
            "                                [--num_reuse_samples NUM_REUSE_SAMPLES]\n",
            "                                [--times_reused TIMES_REUSED] [--balanced_base BALANCED_BASE]\n",
            "                                [--input_int_base INPUT_INT_BASE]\n",
            "                                [--output_int_base OUTPUT_INT_BASE] [--correctQ CORRECTQ]\n",
            "                                [--share_token SHARE_TOKEN] [--transformermode TRANSFORMERMODE]\n",
            "                                [--enc_emb_dim ENC_EMB_DIM] [--dec_emb_dim DEC_EMB_DIM]\n",
            "                                [--n_enc_layers N_ENC_LAYERS] [--n_dec_layers N_DEC_LAYERS]\n",
            "                                [--n_enc_heads N_ENC_HEADS] [--n_dec_heads N_DEC_HEADS]\n",
            "                                [--n_cross_heads N_CROSS_HEADS]\n",
            "                                [--n_enc_hidden_layers N_ENC_HIDDEN_LAYERS]\n",
            "                                [--n_dec_hidden_layers N_DEC_HIDDEN_LAYERS] [--xav_init XAV_INIT]\n",
            "                                [--gelu_activation GELU_ACTIVATION]\n",
            "                                [--norm_attention NORM_ATTENTION] [--dropout DROPOUT]\n",
            "                                [--attention_dropout ATTENTION_DROPOUT]\n",
            "                                [--share_inout_emb SHARE_INOUT_EMB]\n",
            "                                [--sinusoidal_embeddings SINUSOIDAL_EMBEDDINGS]\n",
            "                                [--enc_loop_idx ENC_LOOP_IDX] [--dec_loop_idx DEC_LOOP_IDX]\n",
            "                                [--enc_loops ENC_LOOPS] [--dec_loops DEC_LOOPS] [--gated GATED]\n",
            "                                [--enc_gated ENC_GATED] [--dec_gated DEC_GATED]\n",
            "                                [--scalar_gate SCALAR_GATE] [--enc_act ENC_ACT]\n",
            "                                [--dec_act DEC_ACT] [--act_threshold ACT_THRESHOLD]\n",
            "                                [--act_ponder_coupling ACT_PONDER_COUPLING]\n",
            "                                [--env_base_seed ENV_BASE_SEED] [--batch_size BATCH_SIZE]\n",
            "                                [--optimizer OPTIMIZER] [--weighted_loss WEIGHTED_LOSS]\n",
            "                                [--clip_grad_norm CLIP_GRAD_NORM] [--epoch_size EPOCH_SIZE]\n",
            "                                [--max_epoch MAX_EPOCH] [--stopping_criterion STOPPING_CRITERION]\n",
            "                                [--validation_metrics VALIDATION_METRICS]\n",
            "                                [--accumulate_gradients ACCUMULATE_GRADIENTS]\n",
            "                                [--num_workers NUM_WORKERS] [--beam_eval BEAM_EVAL]\n",
            "                                [--beam_eval_train BEAM_EVAL_TRAIN] [--beam_size BEAM_SIZE]\n",
            "                                [--beam_length_penalty BEAM_LENGTH_PENALTY]\n",
            "                                [--beam_early_stopping BEAM_EARLY_STOPPING]\n",
            "                                [--reload_model RELOAD_MODEL]\n",
            "                                [--reload_checkpoint RELOAD_CHECKPOINT]\n",
            "                                [--freeze_embeddings FREEZE_EMBEDDINGS] [--eval_only EVAL_ONLY]\n",
            "                                [--eval_from_exp EVAL_FROM_EXP] [--eval_data EVAL_DATA]\n",
            "                                [--eval_verbose EVAL_VERBOSE]\n",
            "                                [--eval_verbose_print EVAL_VERBOSE_PRINT] [--eval_size EVAL_SIZE]\n",
            "                                [--distinguisher_size DISTINGUISHER_SIZE]\n",
            "                                [--debug_slurm DEBUG_SLURM] [--debug] [--cpu CPU]\n",
            "                                [--local_rank LOCAL_RANK] [--master_port MASTER_PORT]\n",
            "                                [--windows WINDOWS] [--nvidia_apex NVIDIA_APEX]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-fe6fbe67-959a-49c1-b22e-eba38d741a58.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    }
  ]
}