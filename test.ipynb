{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA+YCAvrxCw6SN8e2YVtSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panperception/SALSA_Test/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SALSA Tests"
      ],
      "metadata": {
        "id": "ANnLAudKsiOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Panperception/SALSA_Test/blob/main/SALSA.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdDawSW7v2-R",
        "outputId": "36559255-de63-4a9f-9899-b630ba825b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-07 04:53:03--  https://github.com/Panperception/SALSA_Test/blob/main/SALSA.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘SALSA.zip’\n",
            "\n",
            "SALSA.zip               [ <=>                ] 219.77K  1.21MB/s    in 0.2s    \n",
            "\n",
            "2025-02-07 04:53:04 (1.21 MB/s) - ‘SALSA.zip’ saved [225045]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip SALSA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toG5o8X7wNsq",
        "outputId": "cdfc4d53-b369-4ed4-a3ec-646902b714f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  SALSA.zip\n",
            "replace .gitignore? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: .gitignore              \n",
            "  inflating: .vscode/launch.json     \n",
            "  inflating: checkpoint/example/test_run/params.pkl  \n",
            "  inflating: checkpoint/example/test_run/train.log  \n",
            "  inflating: CODE_OF_CONDUCT.md      \n",
            "  inflating: CONTRIBUTING.md         \n",
            "  inflating: LICENSE                 \n",
            " extracting: notebooks/analysis_helper/__init__.py  \n",
            "  inflating: notebooks/analysis_helper/db.py  \n",
            "  inflating: notebooks/analysis_helper/parsers.py  \n",
            "  inflating: notebooks/analyze_experiment_logs.ipynb  \n",
            "  inflating: notebooks/distinguisher_helper.py  \n",
            "  inflating: notebooks/run_distinguisher.py  \n",
            "  inflating: notebooks/validate_recovered_secret.ipynb  \n",
            "  inflating: README.md               \n",
            "  inflating: requirements.txt        \n",
            "  inflating: slurm_params/table2_n50.json  \n",
            "  inflating: src/__init__.py         \n",
            "  inflating: src/__pycache__/__init__.cpython-310.pyc  \n",
            "  inflating: src/__pycache__/evaluator.cpython-310.pyc  \n",
            "  inflating: src/__pycache__/logger.cpython-310.pyc  \n",
            "  inflating: src/__pycache__/optim.cpython-310.pyc  \n",
            "  inflating: src/__pycache__/slurm.cpython-310.pyc  \n",
            "  inflating: src/__pycache__/trainer.cpython-310.pyc  \n",
            "  inflating: src/__pycache__/utils.cpython-310.pyc  \n",
            "  inflating: src/envs/__init__.py    \n",
            "  inflating: src/envs/__pycache__/__init__.cpython-310.pyc  \n",
            "  inflating: src/envs/__pycache__/encoders.cpython-310.pyc  \n",
            "  inflating: src/envs/__pycache__/generators.cpython-310.pyc  \n",
            "  inflating: src/envs/__pycache__/lattice.cpython-310.pyc  \n",
            "  inflating: src/envs/encoders.py    \n",
            "  inflating: src/envs/generators.py  \n",
            "  inflating: src/envs/lattice.py     \n",
            "  inflating: src/evaluator.py        \n",
            "  inflating: src/logger.py           \n",
            "  inflating: src/model/__init__.py   \n",
            "  inflating: src/model/__pycache__/__init__.cpython-310.pyc  \n",
            "  inflating: src/model/__pycache__/transformer.cpython-310.pyc  \n",
            "  inflating: src/model/transformer.py  \n",
            "  inflating: src/optim.py            \n",
            "  inflating: src/slurm.py            \n",
            "  inflating: src/trainer.py          \n",
            "  inflating: src/utils.py            \n",
            "  inflating: train.ipynb             \n",
            "  inflating: train.py                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "#\n",
        "# This source code is licensed under the license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "import json\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import src\n",
        "from src.slurm import init_signal_handler, init_distributed_mode\n",
        "from src.utils import bool_flag, initialize_exp\n",
        "from src.model import check_model_params, build_modules\n",
        "from src.envs import ENVS, build_env\n",
        "from src.trainer import Trainer\n",
        "from src.evaluator import Evaluator\n",
        "\n",
        "\n",
        "np.seterr(all='raise')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysdr5p8BxJCd",
        "outputId": "fc801f17-2544-4f04-e738-bf57d2fd0c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parser():\n",
        "    \"\"\"\n",
        "    Generate a parameters parser.\n",
        "    \"\"\"\n",
        "    # parse parameters\n",
        "    parser = argparse.ArgumentParser(description=\"Language transfer\")\n",
        "\n",
        "    # main parameters\n",
        "    parser.add_argument(\"--dump_path\", type=str, default=\"\",\n",
        "                        help=\"Experiment dump path\")\n",
        "    parser.add_argument(\"--exp_name\", type=str, default=\"debug\",\n",
        "                        help=\"Experiment name\")\n",
        "    parser.add_argument(\"--save_periodic\", type=int, default=0,\n",
        "                        help=\"Save the model periodically (0 to disable)\")\n",
        "    parser.add_argument(\"--exp_id\", type=str, default=\"\",\n",
        "                        help=\"Experiment ID\")\n",
        "\n",
        "    # float16 / AMP API\n",
        "    parser.add_argument(\"--fp16\", type=bool_flag, default=False,\n",
        "                        help=\"Run model with float16\")\n",
        "    parser.add_argument(\"--amp\", type=int, default=-1,\n",
        "                        help=\"Use AMP wrapper for float16 / distributed / gradient accumulation. Level of optimization. -1 to disable.\")\n",
        "\n",
        "    # model parameters\n",
        "    parser.add_argument(\"--enc_emb_dim\", type=int, default=1024,\n",
        "                        help=\"Encoder embedding layer size\")\n",
        "    parser.add_argument(\"--dec_emb_dim\", type=int, default=512,\n",
        "                        help=\"Decoder embedding layer size\")\n",
        "    parser.add_argument(\"--n_enc_layers\", type=int, default=2,\n",
        "                        help=\"Number of Transformer layers in the encoder\")\n",
        "    parser.add_argument(\"--n_dec_layers\", type=int, default=2,\n",
        "                        help=\"Number of Transformer layers in the decoder\")\n",
        "    parser.add_argument(\"--n_enc_heads\", type=int, default=16,\n",
        "                        help=\"Number of Transformer encoder heads\")\n",
        "    parser.add_argument(\"--n_dec_heads\", type=int, default=4,\n",
        "                        help=\"Number of Transformer decoder heads\")\n",
        "    parser.add_argument(\"--n_enc_hidden_layers\", type=int, default=1,\n",
        "                        help=\"Number of FFN layers in Transformer encoder\")\n",
        "    parser.add_argument(\"--n_dec_hidden_layers\", type=int, default=1,\n",
        "                        help=\"Number of FFN layers in Transformer decoder\")\n",
        "    parser.add_argument(\"--xav_init\", type=bool_flag, default=False,\n",
        "                        help=\"Xavier initialization for transformer parameters\")\n",
        "    parser.add_argument(\"--gelu_activation\", type=bool_flag, default=False,\n",
        "                        help=\"GELU initialization in FFN layers (else RELU)\")\n",
        "\n",
        "    parser.add_argument(\"--norm_attention\", type=bool_flag, default=False,\n",
        "                        help=\"Normalize attention and train temperaturee in Transformer\")\n",
        "    parser.add_argument(\"--dropout\", type=float, default=0,\n",
        "                        help=\"Dropout\")\n",
        "    parser.add_argument(\"--attention_dropout\", type=float, default=0,\n",
        "                        help=\"Dropout in the attention layer\")\n",
        "    parser.add_argument(\"--share_inout_emb\", type=bool_flag, default=False,\n",
        "                        help=\"Share input and output embeddings\")\n",
        "    parser.add_argument(\"--sinusoidal_embeddings\", type=bool_flag, default=False,\n",
        "                        help=\"Use sinusoidal embeddings\")\n",
        "\n",
        "    # universal transformer parameters\n",
        "    parser.add_argument(\"--enc_loop_idx\", type=int, default=1,\n",
        "                        help=\"Index of the encoder shared weight layers (-1 for none)\")\n",
        "    parser.add_argument(\"--dec_loop_idx\", type=int, default=1,\n",
        "                        help=\"Index of the decoder shared weight layers (-1 for none)\")\n",
        "    parser.add_argument(\"--enc_loops\", type=int, default=2,\n",
        "                        help=\"Fixed/max nr of train passes through the encoder loop\")\n",
        "    parser.add_argument(\"--dec_loops\", type=int, default=8,\n",
        "                        help=\"Fixed/max nr of train passes through the decoder loop\")\n",
        "    parser.add_argument(\"--gated\", type=bool_flag, default=True,\n",
        "                        help=\"Gated loop layers\")\n",
        "    parser.add_argument(\"--enc_gated\", type=bool_flag, default=False,\n",
        "                        help=\"All encoder layers gated\")\n",
        "    parser.add_argument(\"--dec_gated\", type=bool_flag, default=False,\n",
        "                        help=\"All decoder layers gated\")\n",
        "    parser.add_argument(\"--scalar_gate\", type=bool_flag, default=False,\n",
        "                        help=\"Scalar gates\")\n",
        "    # ACT\n",
        "    parser.add_argument(\"--enc_act\", type=bool_flag, default=False,\n",
        "                        help=\"Encoder looped layer ACT\")\n",
        "    parser.add_argument(\"--dec_act\", type=bool_flag, default=False,\n",
        "                        help=\"Decoder looped layer ACT\")\n",
        "    parser.add_argument(\"--act_threshold\", type=float, default=0.01,\n",
        "                        help=\"Prob threshold for ACT\")\n",
        "    parser.add_argument(\"--act_ponder_coupling\", type=float, default=0.05,\n",
        "                        help=\"Ponder loss coupling for ACT\")\n",
        "\n",
        "    # training parameters\n",
        "    parser.add_argument(\"--env_base_seed\", type=int, default=0,\n",
        "                        help=\"Base seed for environments (-1 to use timestamp seed)\")\n",
        "    parser.add_argument(\"--max_len\", type=int, default=512,\n",
        "                        help=\"Maximum sequences length\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=128,\n",
        "                        help=\"Number of sentences per batch\")\n",
        "    parser.add_argument(\"--batch_size_eval\", type=int, default=64,\n",
        "                        help=\"Number of sentences per batch during evaluation\")\n",
        "    parser.add_argument(\"--optimizer\", type=str, default=\"adam_warmup,lr=0.00001,warmup_updates=8000,weight_decay=0.99\",\n",
        "                        help=\"Optimizer (SGD / RMSprop / Adam, etc.)\")\n",
        "    parser.add_argument(\"--weighted_loss\", type=bool_flag, default=False,\n",
        "                        help='Weight loss to emphasize higher bits?')\n",
        "    parser.add_argument(\"--clip_grad_norm\", type=float, default=5,\n",
        "                        help=\"Clip gradients norm (0 to disable)\")\n",
        "    parser.add_argument(\"--epoch_size\", type=int, default=300000,\n",
        "                        help=\"Epoch size / evaluation frequency\")\n",
        "    parser.add_argument(\"--max_epoch\", type=int, default=100000,\n",
        "                        help=\"Maximum epoch size\")\n",
        "    parser.add_argument(\"--stopping_criterion\", type=str, default=\"_valid_lattice_xe_loss,1,75\",\n",
        "                        help=\"Stopping criterion, and number of non-increase before stopping the experiment\")\n",
        "    parser.add_argument(\"--secret_stop\", type=bool_flag, default=True, help=\"stop when secret is found?\")\n",
        "    parser.add_argument(\"--validation_metrics\", type=str, default=\"_valid_lattice_xe_loss\",\n",
        "                        help=\"Validation metrics\")\n",
        "    parser.add_argument(\"--accumulate_gradients\", type=int, default=1,\n",
        "                        help=\"Accumulate model gradients over N iterations (N times larger batch sizes)\")\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=10,\n",
        "                        help=\"Number of CPU workers for DataLoader\")\n",
        "\n",
        "    # export data / reload it\n",
        "    parser.add_argument(\"--export_data\", type=bool_flag, default=False,\n",
        "                        help=\"Export data and disable training.\")\n",
        "    parser.add_argument(\"--reload_data\", type=str, default=\"\",\n",
        "                        help=\"Load dataset from the disk (task1,train_path1,valid_path1,test_path1;task2,train_path2,valid_path2,test_path2)\")\n",
        "    parser.add_argument(\"--reload_size\", type=int, default=-1,\n",
        "                        help=\"Reloaded training set size (-1 for everything)\")\n",
        "    parser.add_argument(\"--batch_load\", type=bool_flag, default=False,\n",
        "                        help=\"Load training set by batches (of size reload_size).\")\n",
        "\n",
        "    # environment parameters\n",
        "    parser.add_argument(\"--env_name\", type=str, default=\"lattice\",\n",
        "                        help=\"Environment name\")\n",
        "    ENVS[parser.parse_known_args()[0].env_name].register_args(parser)\n",
        "\n",
        "    # tasks\n",
        "    parser.add_argument(\"--tasks\", type=str, default=\"lattice\",\n",
        "                        help=\"Tasks\")\n",
        "\n",
        "    # beam search configuration\n",
        "    parser.add_argument(\"--beam_eval\", type=bool_flag, default=True,\n",
        "                        help=\"Evaluate with beam search decoding.\")\n",
        "    parser.add_argument(\"--beam_eval_train\", type=int, default=0,\n",
        "                        help=\"At training time, number of validation equations to test the model on using beam search (-1 for everything, 0 to disable)\")\n",
        "    parser.add_argument(\"--beam_size\", type=int, default=1,\n",
        "                        help=\"Beam size, default = 1 (greedy decoding)\")\n",
        "    parser.add_argument(\"--beam_length_penalty\", type=float, default=1,\n",
        "                        help=\"Length penalty, values < 1.0 favor shorter sentences, while values > 1.0 favor longer ones.\")\n",
        "    parser.add_argument(\"--beam_early_stopping\", type=bool_flag, default=True,\n",
        "                        help=\"Early stopping, stop as soon as we have `beam_size` hypotheses, although longer ones may have better scores.\")\n",
        "\n",
        "    # reload pretrained model / checkpoint\n",
        "    parser.add_argument(\"--reload_model\", type=str, default=\"\",\n",
        "                        help=\"Reload a pretrained model\")\n",
        "    parser.add_argument(\"--reload_checkpoint\", type=str, default=\"\",\n",
        "                        help=\"Reload a checkpoint\")\n",
        "    parser.add_argument(\"--freeze_embeddings\", type=bool_flag, default=\"False\",\n",
        "                        help=\"Freeze embeddings for retraining?\")\n",
        "\n",
        "    # evaluation\n",
        "    parser.add_argument(\"--eval_only\", type=bool_flag, default=False,\n",
        "                        help=\"Only run evaluations\")\n",
        "    parser.add_argument(\"--eval_from_exp\", type=str, default=\"\",\n",
        "                        help=\"Path of experiment to use\")\n",
        "    parser.add_argument(\"--eval_data\", type=str, default=\"\",\n",
        "                        help=\"Path of data to eval\")\n",
        "    parser.add_argument(\"--eval_verbose\", type=int, default=0,\n",
        "                        help=\"Export evaluation details\")\n",
        "    parser.add_argument(\"--eval_verbose_print\", type=bool_flag, default=False,\n",
        "                        help=\"Print evaluation details\")\n",
        "\n",
        "    # debug\n",
        "    parser.add_argument(\"--debug_slurm\", type=bool_flag, default=False,\n",
        "                        help=\"Debug multi-GPU / multi-node within a SLURM job\")\n",
        "    parser.add_argument(\"--debug\", help=\"Enable all debug flags\",\n",
        "                        action=\"store_true\")\n",
        "\n",
        "    # CPU / multi-gpu / multi-node\n",
        "    parser.add_argument(\"--cpu\", type=bool_flag, default=False,\n",
        "                        help=\"Run on CPU\")\n",
        "    parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
        "                        help=\"Multi-GPU - Local rank\")\n",
        "    parser.add_argument(\"--master_port\", type=int, default=-1,\n",
        "                        help=\"Master port (for multi-node SLURM jobs)\")\n",
        "    parser.add_argument(\"--windows\", type=bool_flag, default=False,\n",
        "                        help=\"Windows version (no multiprocessing for eval)\")\n",
        "    parser.add_argument(\"--nvidia_apex\", type=bool_flag, default=False,\n",
        "                        help=\"NVIDIA version of apex\")\n",
        "\n",
        "    return parser\n"
      ],
      "metadata": {
        "id": "j2nGU98mxg3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate parser / parse parameters\n",
        "parser = get_parser()\n",
        "params = parser.parse_args()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eOGKdZUZyeLz",
        "outputId": "bfe03d69-c4f2-4f81-d7fb-35efed1d1895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--dump_path DUMP_PATH] [--exp_name EXP_NAME]\n",
            "                                [--save_periodic SAVE_PERIODIC] [--exp_id EXP_ID] [--fp16 FP16]\n",
            "                                [--amp AMP] [--enc_emb_dim ENC_EMB_DIM]\n",
            "                                [--dec_emb_dim DEC_EMB_DIM] [--n_enc_layers N_ENC_LAYERS]\n",
            "                                [--n_dec_layers N_DEC_LAYERS] [--n_enc_heads N_ENC_HEADS]\n",
            "                                [--n_dec_heads N_DEC_HEADS]\n",
            "                                [--n_enc_hidden_layers N_ENC_HIDDEN_LAYERS]\n",
            "                                [--n_dec_hidden_layers N_DEC_HIDDEN_LAYERS] [--xav_init XAV_INIT]\n",
            "                                [--gelu_activation GELU_ACTIVATION]\n",
            "                                [--norm_attention NORM_ATTENTION] [--dropout DROPOUT]\n",
            "                                [--attention_dropout ATTENTION_DROPOUT]\n",
            "                                [--share_inout_emb SHARE_INOUT_EMB]\n",
            "                                [--sinusoidal_embeddings SINUSOIDAL_EMBEDDINGS]\n",
            "                                [--enc_loop_idx ENC_LOOP_IDX] [--dec_loop_idx DEC_LOOP_IDX]\n",
            "                                [--enc_loops ENC_LOOPS] [--dec_loops DEC_LOOPS] [--gated GATED]\n",
            "                                [--enc_gated ENC_GATED] [--dec_gated DEC_GATED]\n",
            "                                [--scalar_gate SCALAR_GATE] [--enc_act ENC_ACT]\n",
            "                                [--dec_act DEC_ACT] [--act_threshold ACT_THRESHOLD]\n",
            "                                [--act_ponder_coupling ACT_PONDER_COUPLING]\n",
            "                                [--env_base_seed ENV_BASE_SEED] [--max_len MAX_LEN]\n",
            "                                [--batch_size BATCH_SIZE] [--batch_size_eval BATCH_SIZE_EVAL]\n",
            "                                [--optimizer OPTIMIZER] [--weighted_loss WEIGHTED_LOSS]\n",
            "                                [--clip_grad_norm CLIP_GRAD_NORM] [--epoch_size EPOCH_SIZE]\n",
            "                                [--max_epoch MAX_EPOCH] [--stopping_criterion STOPPING_CRITERION]\n",
            "                                [--secret_stop SECRET_STOP]\n",
            "                                [--validation_metrics VALIDATION_METRICS]\n",
            "                                [--accumulate_gradients ACCUMULATE_GRADIENTS]\n",
            "                                [--num_workers NUM_WORKERS] [--export_data EXPORT_DATA]\n",
            "                                [--reload_data RELOAD_DATA] [--reload_size RELOAD_SIZE]\n",
            "                                [--batch_load BATCH_LOAD] [--env_name ENV_NAME]\n",
            "                                [--eval_size EVAL_SIZE] [--operation OPERATION]\n",
            "                                [--generator GENERATOR] [--N N] [--Q Q] [--reuse REUSE]\n",
            "                                [--num_reuse_samples NUM_REUSE_SAMPLES]\n",
            "                                [--times_reused TIMES_REUSED] [--K K] [--percQ_bound PERCQ_BOUND]\n",
            "                                [--maxQ_prob MAXQ_PROB] [--error ERROR] [--sigma SIGMA]\n",
            "                                [--correctQ CORRECTQ] [--secret SECRET] [--secrettype SECRETTYPE]\n",
            "                                [--sparsity SPARSITY] [--density DENSITY] [--hamming HAMMING]\n",
            "                                [--balanced_base BALANCED_BASE] [--input_int_base INPUT_INT_BASE]\n",
            "                                [--output_int_base OUTPUT_INT_BASE]\n",
            "                                [--max_output_len MAX_OUTPUT_LEN] [--no_separator NO_SEPARATOR]\n",
            "                                [--tasks TASKS] [--beam_eval BEAM_EVAL]\n",
            "                                [--beam_eval_train BEAM_EVAL_TRAIN] [--beam_size BEAM_SIZE]\n",
            "                                [--beam_length_penalty BEAM_LENGTH_PENALTY]\n",
            "                                [--beam_early_stopping BEAM_EARLY_STOPPING]\n",
            "                                [--reload_model RELOAD_MODEL]\n",
            "                                [--reload_checkpoint RELOAD_CHECKPOINT]\n",
            "                                [--freeze_embeddings FREEZE_EMBEDDINGS] [--eval_only EVAL_ONLY]\n",
            "                                [--eval_from_exp EVAL_FROM_EXP] [--eval_data EVAL_DATA]\n",
            "                                [--eval_verbose EVAL_VERBOSE]\n",
            "                                [--eval_verbose_print EVAL_VERBOSE_PRINT]\n",
            "                                [--debug_slurm DEBUG_SLURM] [--debug] [--cpu CPU]\n",
            "                                [--local_rank LOCAL_RANK] [--master_port MASTER_PORT]\n",
            "                                [--windows WINDOWS] [--nvidia_apex NVIDIA_APEX]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-5fc83e3e-815f-448e-a8a7-b45fda8fd618.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval-only mode.\n",
        "if params.eval_only and params.eval_from_exp != \"\":\n",
        "    # read params from pickle\n",
        "    pickle_file = params.eval_from_exp + \"/params.pkl\"\n",
        "    assert os.path.isfile(pickle_file)\n",
        "    pk = pickle.load(open(pickle_file, 'rb'))\n",
        "    pickled_args = pk.__dict__\n",
        "    del pickled_args['exp_id']\n",
        "    for p in params.__dict__:\n",
        "        if p in pickled_args:\n",
        "            params.__dict__[p] = pickled_args[p]\n",
        "\n",
        "    params.eval_only = True\n",
        "    params.reload_model = params.eval_from_exp + '/best-' + params.validation_metrics + '.pth'\n",
        "    params.eval_size = None\n",
        "    params.reload_data = params.tasks + ',' + params.eval_data + ',' + params.eval_data + ',' + params.eval_data\n",
        "    params.is_slurm_job = False\n",
        "    params.local_rank = -1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "MNml7NbtyndY",
        "outputId": "97a4ad82-c4a1-4773-c53a-e83031c46efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'params' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b8d9916ae086>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Eval-only mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_only\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_from_exp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# read params from pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpickle_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_from_exp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/params.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == '__main__':\n",
        "\n",
        "    # generate parser / parse parameters\n",
        "    parser = get_parser()\n",
        "    params = parser.parse_args()\n",
        "\n",
        "\n",
        "    # debug mode\n",
        "    if params.debug:\n",
        "        params.exp_name = 'debug'\n",
        "        if params.exp_id == '':\n",
        "            params.exp_id = 'debug_%08i' % random.randint(0, 100000000)\n",
        "        params.debug_slurm = True\n",
        "\n",
        "    # check parameters\n",
        "    check_model_params(params)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "fFvMZVarwvao",
        "outputId": "bbd6474f-4c0a-4aa6-8f36-94db5a9837f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-35-1e3d189c30aa>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-1e3d189c30aa>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    parser = get_parser()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # run experiment\n",
        "\n",
        "    # Initialize the dump path.\n",
        "    if params.export_data:\n",
        "        e = '_error' if params.error else ''\n",
        "        params.dump_path = params.dump_path\n",
        "        params.exp_name = 'data'\n",
        "        params.exp_id = f'N={params.N}_Q={params.Q}{e}/'\n",
        "\n",
        "    # initialize the multi-GPU / multi-node training\n",
        "    # initialize experiment / SLURM signal handler for time limit / pre-emption\n",
        "    init_distributed_mode(params)\n",
        "    logger = initialize_exp(params)\n",
        "    if params.is_slurm_job:\n",
        "        init_signal_handler()\n",
        "\n",
        "    # CPU / CUDA\n",
        "    if params.cpu:\n",
        "        assert not params.multi_gpu\n",
        "    else:\n",
        "        assert torch.cuda.is_available()\n",
        "    src.utils.CUDA = not params.cpu\n",
        "\n",
        "    # build environment / modules / trainer / evaluator\n",
        "    env = build_env(params)\n",
        "    modules = build_modules(env, params)\n",
        "    trainer = Trainer(modules, env, params)\n",
        "    evaluator = Evaluator(trainer)\n",
        "\n",
        "    # evaluation\n",
        "    if params.eval_only:\n",
        "        scores = evaluator.run_all_evals()\n",
        "        for k, v in scores.items():\n",
        "            logger.info(\"%s -> %.6f\" % (k, v))\n",
        "        logger.info(\"__log__:%s\" % json.dumps(scores))\n",
        "        exit()\n",
        "\n",
        "    # training\n",
        "    for _ in range(params.max_epoch):\n",
        "\n",
        "        logger.info(\"============ Starting epoch %i ... ============\" % trainer.epoch)\n",
        "\n",
        "        trainer.n_equations = 0\n",
        "\n",
        "        while trainer.n_equations < trainer.epoch_size:\n",
        "\n",
        "            # training steps\n",
        "            for task_id in np.random.permutation(len(params.tasks)):\n",
        "                task = params.tasks[task_id]\n",
        "                if params.export_data:\n",
        "                    trainer.export_data(task)\n",
        "                else:\n",
        "                    trainer.enc_dec_step(task)\n",
        "                trainer.iter()\n",
        "\n",
        "        logger.info(\"============ End of epoch %i ============\" % trainer.epoch)\n",
        "\n",
        "        # evaluate perplexity\n",
        "        scores = evaluator.run_all_evals()\n",
        "\n",
        "        # print / JSON log\n",
        "        if params.is_master:\n",
        "            logger.info(\"__log__:%s\" % json.dumps(scores))\n",
        "\n",
        "        # end of epoch\n",
        "        trainer.save_best_model(scores)\n",
        "        trainer.save_periodic()\n",
        "        trainer.end_epoch(scores)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "rQoNi0BAyDsL",
        "outputId": "6687e650-9aaa-47c6-f430-e751a8577653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'params' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d61c59401610>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialize the dump path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_error'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHt8zkCwr2kG",
        "outputId": "28fa1ef6-8da6-435a-cf76-35e53c3aa1a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ],
      "source": [
        "!conda create --name lattice_env --file requirements.txt\n",
        "!conda activate lattice_env.\n",
        "\n"
      ]
    }
  ]
}